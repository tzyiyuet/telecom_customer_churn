# 3. Description of Dataset & Variables
The dataset obtained is published on Kaggle (https://www.kaggle.com/blastchar/telco-customer-churn), an online data platform that provides free access to thousands of datasets. The dataset that’s used contains relevant information related to customer churn of a telecommunication company. It contains 7,043 rows, and each row represents a unique customer and its specific attributes. 

In terms of features, the dataset contains 21 different variables, which could be further split into eighteen categorical variables and three numerical variables. Among the eighteen categorical variables, couples of them can be further converted into binary variables. Since our analysis focuses on customer churn, our dependent variable would be “churn,” which is recorded as a dichotomous variable. Other crucial variables would be those that give us insights and a better understanding of what makes a customer stay or leave the company. Such variables could be separated into three categories. First, the customer account information includes variables such as their tenure, the type of contracts, the method of payments, monthly and total charges. The second category is pertaining to the demography of each segment with variables such as age and gender. Finally, our last category would be the type of services the customer signed-up for, for example, phone services, number of lines, internet services and security services. 

After doing a thoughtful evaluation of the 7,043 rows and the different features, even if this dataset had a high level of completeness, we spotted that certain missing numerical values existed and would affect the subsequent analysis. Accordingly, the missing values were replaced by the mean of the non-missing values in each column separately and independently from the others. 

In addition, after we categorizing the dataset by “churn” and “no churn”, we realized the dataset contains 27% of clients’records, which were churn, and 73% of the clients’ records were “no churn”. This result indicated that our sample was unbalanced. Since an unbalanced dataset would bias the prediction model towards the more common class in machine learning (https://shiring.github.io/machine_learning/2017/04/02/unbalanced), we used an under-sampling method and made the dataset with 50% of churn records and 50% of non-churn records. Finally, the updated dataset can be considered as pertinent and functional and had a standard format for each variable that indicated its conformity. There was neither conflict within data values nor duplication of records.

We import sklearn modules to run the logistic regression. Meanwhile, we also import numpy, seaborn, matplotlib modules to draw the graphs, which help to understand the data interpretation.
